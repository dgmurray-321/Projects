{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd449896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import keras as k \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from os import path\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99dc9d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_2661/98304411.py:2: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "tf.set_random_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e1e9a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Assignment 3 - MLPs On Iris With Keras JPN.ipynb'   Untitled.ipynb\r\n",
      " Iris.csv\t\t\t\t\t     Untitled1.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5df7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./Iris.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3144cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "(150, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0fe8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0            5.1           3.5            1.4           0.2\n",
      "1            4.9           3.0            1.4           0.2\n",
      "2            4.7           3.2            1.3           0.2\n",
      "3            4.6           3.1            1.5           0.2\n",
      "4            5.0           3.6            1.4           0.2\n",
      "\n",
      "0    Iris-setosa\n",
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "Name: Species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns = ['Id', 'Species'], axis = 1)\n",
    "y = df['Species']\n",
    "\n",
    "print(x.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f2f83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x training: (90, 4)\n",
      "\n",
      "y training: (90,)\n",
      "\n",
      "x test: (24, 4)\n",
      "\n",
      "y validation: (36,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size = .40, random_state=7)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val,y_val, test_size = .40, random_state = 7)\n",
    "\n",
    "print(\"x training:\", x_train.shape)\n",
    "print()\n",
    "print(\"y training:\",y_train.shape)\n",
    "print()\n",
    "print(\"x test:\",x_test.shape)\n",
    "print()\n",
    "print(\"y validation:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f830a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "0            0                1               0\n",
      "1            0                1               0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train = lb.fit_transform(y_train)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns = lb.classes_)\n",
    "\n",
    "y_val = lb.transform(y_val)\n",
    "y_val = pd.DataFrame(y_val, columns = lb.classes_)\n",
    "\n",
    "y_test = lb.transform(y_test)\n",
    "y_test = pd.DataFrame(y_test, columns = lb.classes_)\n",
    "print(lb.classes_)\n",
    "print(y_test.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d2bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "def model_2():\n",
    "    input_layer = Input(shape=(4,))\n",
    "    hidden_layer1 = Dense(10, activation='relu')(input_layer)\n",
    "    hidden_layer2 = Dense(9, activation= 'relu')(hidden_layer1)\n",
    "    output_layer = Dense(3, activation = 'softmax')(hidden_layer2)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03676e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 36 samples\n",
      "Epoch 1/150\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 1.6417 - accuracy: 0.3444 - val_loss: 1.5497 - val_accuracy: 0.3056\n",
      "Epoch 2/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 1.3636 - accuracy: 0.3444 - val_loss: 1.2800 - val_accuracy: 0.3056\n",
      "Epoch 3/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 1.1503 - accuracy: 0.3444 - val_loss: 1.0921 - val_accuracy: 0.3056\n",
      "Epoch 4/150\n",
      "90/90 [==============================] - 0s 245us/step - loss: 1.0065 - accuracy: 0.3778 - val_loss: 0.9750 - val_accuracy: 0.4722\n",
      "Epoch 5/150\n",
      "90/90 [==============================] - 0s 255us/step - loss: 0.9328 - accuracy: 0.5333 - val_loss: 0.9296 - val_accuracy: 0.6944\n",
      "Epoch 6/150\n",
      "90/90 [==============================] - 0s 245us/step - loss: 0.9073 - accuracy: 0.6556 - val_loss: 0.9112 - val_accuracy: 0.6944\n",
      "Epoch 7/150\n",
      "90/90 [==============================] - 0s 240us/step - loss: 0.8912 - accuracy: 0.6778 - val_loss: 0.8968 - val_accuracy: 0.6944\n",
      "Epoch 8/150\n",
      "90/90 [==============================] - 0s 251us/step - loss: 0.8765 - accuracy: 0.5778 - val_loss: 0.8823 - val_accuracy: 0.4167\n",
      "Epoch 9/150\n",
      "90/90 [==============================] - 0s 244us/step - loss: 0.8607 - accuracy: 0.5444 - val_loss: 0.8692 - val_accuracy: 0.3889\n",
      "Epoch 10/150\n",
      "90/90 [==============================] - 0s 256us/step - loss: 0.8475 - accuracy: 0.5222 - val_loss: 0.8569 - val_accuracy: 0.4167\n",
      "Epoch 11/150\n",
      "90/90 [==============================] - 0s 240us/step - loss: 0.8346 - accuracy: 0.5111 - val_loss: 0.8454 - val_accuracy: 0.4722\n",
      "Epoch 12/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.8225 - accuracy: 0.5778 - val_loss: 0.8337 - val_accuracy: 0.5278\n",
      "Epoch 13/150\n",
      "90/90 [==============================] - 0s 244us/step - loss: 0.8101 - accuracy: 0.5778 - val_loss: 0.8219 - val_accuracy: 0.5000\n",
      "Epoch 14/150\n",
      "90/90 [==============================] - 0s 246us/step - loss: 0.7981 - accuracy: 0.5778 - val_loss: 0.8106 - val_accuracy: 0.5278\n",
      "Epoch 15/150\n",
      "90/90 [==============================] - 0s 237us/step - loss: 0.7864 - accuracy: 0.6111 - val_loss: 0.7989 - val_accuracy: 0.5556\n",
      "Epoch 16/150\n",
      "90/90 [==============================] - 0s 236us/step - loss: 0.7746 - accuracy: 0.5778 - val_loss: 0.7879 - val_accuracy: 0.5278\n",
      "Epoch 17/150\n",
      "90/90 [==============================] - 0s 235us/step - loss: 0.7628 - accuracy: 0.5778 - val_loss: 0.7766 - val_accuracy: 0.5278\n",
      "Epoch 18/150\n",
      "90/90 [==============================] - 0s 234us/step - loss: 0.7513 - accuracy: 0.5778 - val_loss: 0.7652 - val_accuracy: 0.5278\n",
      "Epoch 19/150\n",
      "90/90 [==============================] - 0s 238us/step - loss: 0.7400 - accuracy: 0.5778 - val_loss: 0.7540 - val_accuracy: 0.5278\n",
      "Epoch 20/150\n",
      "90/90 [==============================] - 0s 250us/step - loss: 0.7285 - accuracy: 0.5444 - val_loss: 0.7428 - val_accuracy: 0.4444\n",
      "Epoch 21/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 0.7172 - accuracy: 0.5111 - val_loss: 0.7314 - val_accuracy: 0.6944\n",
      "Epoch 22/150\n",
      "90/90 [==============================] - 0s 235us/step - loss: 0.7067 - accuracy: 0.6778 - val_loss: 0.7202 - val_accuracy: 0.6944\n",
      "Epoch 23/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.6951 - accuracy: 0.6778 - val_loss: 0.7094 - val_accuracy: 0.6944\n",
      "Epoch 24/150\n",
      "90/90 [==============================] - 0s 246us/step - loss: 0.6842 - accuracy: 0.6778 - val_loss: 0.6987 - val_accuracy: 0.6944\n",
      "Epoch 25/150\n",
      "90/90 [==============================] - 0s 253us/step - loss: 0.6737 - accuracy: 0.6778 - val_loss: 0.6877 - val_accuracy: 0.6944\n",
      "Epoch 26/150\n",
      "90/90 [==============================] - 0s 243us/step - loss: 0.6632 - accuracy: 0.6778 - val_loss: 0.6772 - val_accuracy: 0.6944\n",
      "Epoch 27/150\n",
      "90/90 [==============================] - 0s 247us/step - loss: 0.6535 - accuracy: 0.6778 - val_loss: 0.6677 - val_accuracy: 0.6944\n",
      "Epoch 28/150\n",
      "90/90 [==============================] - 0s 258us/step - loss: 0.6433 - accuracy: 0.6778 - val_loss: 0.6577 - val_accuracy: 0.6944\n",
      "Epoch 29/150\n",
      "90/90 [==============================] - 0s 279us/step - loss: 0.6343 - accuracy: 0.6778 - val_loss: 0.6475 - val_accuracy: 0.6944\n",
      "Epoch 30/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 0.6245 - accuracy: 0.6778 - val_loss: 0.6385 - val_accuracy: 0.6944\n",
      "Epoch 31/150\n",
      "90/90 [==============================] - 0s 244us/step - loss: 0.6163 - accuracy: 0.6778 - val_loss: 0.6303 - val_accuracy: 0.6944\n",
      "Epoch 32/150\n",
      "90/90 [==============================] - 0s 243us/step - loss: 0.6076 - accuracy: 0.6778 - val_loss: 0.6209 - val_accuracy: 0.6944\n",
      "Epoch 33/150\n",
      "90/90 [==============================] - 0s 246us/step - loss: 0.5994 - accuracy: 0.6778 - val_loss: 0.6131 - val_accuracy: 0.6944\n",
      "Epoch 34/150\n",
      "90/90 [==============================] - 0s 233us/step - loss: 0.5912 - accuracy: 0.6778 - val_loss: 0.6051 - val_accuracy: 0.6944\n",
      "Epoch 35/150\n",
      "90/90 [==============================] - 0s 243us/step - loss: 0.5840 - accuracy: 0.6778 - val_loss: 0.5980 - val_accuracy: 0.6944\n",
      "Epoch 36/150\n",
      "90/90 [==============================] - 0s 251us/step - loss: 0.5770 - accuracy: 0.6778 - val_loss: 0.5908 - val_accuracy: 0.6944\n",
      "Epoch 37/150\n",
      "90/90 [==============================] - 0s 243us/step - loss: 0.5704 - accuracy: 0.6778 - val_loss: 0.5839 - val_accuracy: 0.6944\n",
      "Epoch 38/150\n",
      "90/90 [==============================] - 0s 234us/step - loss: 0.5641 - accuracy: 0.6778 - val_loss: 0.5773 - val_accuracy: 0.6944\n",
      "Epoch 39/150\n",
      "90/90 [==============================] - 0s 237us/step - loss: 0.5576 - accuracy: 0.6778 - val_loss: 0.5716 - val_accuracy: 0.6944\n",
      "Epoch 40/150\n",
      "90/90 [==============================] - 0s 245us/step - loss: 0.5520 - accuracy: 0.6778 - val_loss: 0.5664 - val_accuracy: 0.6944\n",
      "Epoch 41/150\n",
      "90/90 [==============================] - 0s 238us/step - loss: 0.5462 - accuracy: 0.6778 - val_loss: 0.5609 - val_accuracy: 0.6944\n",
      "Epoch 42/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 0.5412 - accuracy: 0.6778 - val_loss: 0.5558 - val_accuracy: 0.6944\n",
      "Epoch 43/150\n",
      "90/90 [==============================] - 0s 236us/step - loss: 0.5362 - accuracy: 0.6778 - val_loss: 0.5507 - val_accuracy: 0.6944\n",
      "Epoch 44/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 0.5318 - accuracy: 0.6778 - val_loss: 0.5459 - val_accuracy: 0.6944\n",
      "Epoch 45/150\n",
      "90/90 [==============================] - 0s 237us/step - loss: 0.5271 - accuracy: 0.6778 - val_loss: 0.5417 - val_accuracy: 0.6944\n",
      "Epoch 46/150\n",
      "90/90 [==============================] - 0s 235us/step - loss: 0.5235 - accuracy: 0.6778 - val_loss: 0.5381 - val_accuracy: 0.6944\n",
      "Epoch 47/150\n",
      "90/90 [==============================] - 0s 253us/step - loss: 0.5189 - accuracy: 0.6778 - val_loss: 0.5336 - val_accuracy: 0.6944\n",
      "Epoch 48/150\n",
      "90/90 [==============================] - 0s 251us/step - loss: 0.5153 - accuracy: 0.6778 - val_loss: 0.5298 - val_accuracy: 0.6944\n",
      "Epoch 49/150\n",
      "90/90 [==============================] - 0s 234us/step - loss: 0.5117 - accuracy: 0.6778 - val_loss: 0.5259 - val_accuracy: 0.6944\n",
      "Epoch 50/150\n",
      "90/90 [==============================] - 0s 259us/step - loss: 0.5077 - accuracy: 0.6778 - val_loss: 0.5226 - val_accuracy: 0.6944\n",
      "Epoch 51/150\n",
      "90/90 [==============================] - 0s 251us/step - loss: 0.5046 - accuracy: 0.6778 - val_loss: 0.5193 - val_accuracy: 0.6944\n",
      "Epoch 52/150\n",
      "90/90 [==============================] - 0s 261us/step - loss: 0.5011 - accuracy: 0.6778 - val_loss: 0.5153 - val_accuracy: 0.6944\n",
      "Epoch 53/150\n",
      "90/90 [==============================] - 0s 246us/step - loss: 0.4976 - accuracy: 0.6778 - val_loss: 0.5122 - val_accuracy: 0.6944\n",
      "Epoch 54/150\n",
      "90/90 [==============================] - 0s 256us/step - loss: 0.4944 - accuracy: 0.6778 - val_loss: 0.5090 - val_accuracy: 0.6944\n",
      "Epoch 55/150\n",
      "90/90 [==============================] - 0s 253us/step - loss: 0.4913 - accuracy: 0.6778 - val_loss: 0.5058 - val_accuracy: 0.6944\n",
      "Epoch 56/150\n",
      "90/90 [==============================] - 0s 252us/step - loss: 0.4886 - accuracy: 0.6778 - val_loss: 0.5021 - val_accuracy: 0.6944\n",
      "Epoch 57/150\n",
      "90/90 [==============================] - 0s 253us/step - loss: 0.4857 - accuracy: 0.6889 - val_loss: 0.4989 - val_accuracy: 0.6944\n",
      "Epoch 58/150\n",
      "90/90 [==============================] - 0s 255us/step - loss: 0.4823 - accuracy: 0.6889 - val_loss: 0.4959 - val_accuracy: 0.6944\n",
      "Epoch 59/150\n",
      "90/90 [==============================] - 0s 251us/step - loss: 0.4790 - accuracy: 0.6889 - val_loss: 0.4924 - val_accuracy: 0.6944\n",
      "Epoch 60/150\n",
      "90/90 [==============================] - 0s 259us/step - loss: 0.4759 - accuracy: 0.7000 - val_loss: 0.4885 - val_accuracy: 0.6944\n",
      "Epoch 61/150\n",
      "90/90 [==============================] - 0s 269us/step - loss: 0.4729 - accuracy: 0.7000 - val_loss: 0.4847 - val_accuracy: 0.6944\n",
      "Epoch 62/150\n",
      "90/90 [==============================] - 0s 263us/step - loss: 0.4695 - accuracy: 0.7222 - val_loss: 0.4814 - val_accuracy: 0.7222\n",
      "Epoch 63/150\n",
      "90/90 [==============================] - 0s 264us/step - loss: 0.4666 - accuracy: 0.7333 - val_loss: 0.4779 - val_accuracy: 0.7222\n",
      "Epoch 64/150\n",
      "90/90 [==============================] - 0s 255us/step - loss: 0.4632 - accuracy: 0.7333 - val_loss: 0.4743 - val_accuracy: 0.7222\n",
      "Epoch 65/150\n",
      "90/90 [==============================] - 0s 254us/step - loss: 0.4600 - accuracy: 0.7444 - val_loss: 0.4705 - val_accuracy: 0.7222\n",
      "Epoch 66/150\n",
      "90/90 [==============================] - 0s 250us/step - loss: 0.4567 - accuracy: 0.7556 - val_loss: 0.4663 - val_accuracy: 0.7500\n",
      "Epoch 67/150\n",
      "90/90 [==============================] - 0s 257us/step - loss: 0.4535 - accuracy: 0.7667 - val_loss: 0.4621 - val_accuracy: 0.7778\n",
      "Epoch 68/150\n",
      "90/90 [==============================] - 0s 244us/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.4577 - val_accuracy: 0.7778\n",
      "Epoch 69/150\n",
      "90/90 [==============================] - 0s 248us/step - loss: 0.4466 - accuracy: 0.8111 - val_loss: 0.4537 - val_accuracy: 0.8056\n",
      "Epoch 70/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 0.4428 - accuracy: 0.8667 - val_loss: 0.4501 - val_accuracy: 0.8056\n",
      "Epoch 71/150\n",
      "90/90 [==============================] - 0s 246us/step - loss: 0.4391 - accuracy: 0.8667 - val_loss: 0.4457 - val_accuracy: 0.8056\n",
      "Epoch 72/150\n",
      "90/90 [==============================] - 0s 255us/step - loss: 0.4357 - accuracy: 0.8667 - val_loss: 0.4415 - val_accuracy: 0.9167\n",
      "Epoch 73/150\n",
      "90/90 [==============================] - 0s 250us/step - loss: 0.4325 - accuracy: 0.8889 - val_loss: 0.4374 - val_accuracy: 0.9444\n",
      "Epoch 74/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.4280 - accuracy: 0.8889 - val_loss: 0.4330 - val_accuracy: 0.9167\n",
      "Epoch 75/150\n",
      "90/90 [==============================] - 0s 239us/step - loss: 0.4248 - accuracy: 0.8889 - val_loss: 0.4292 - val_accuracy: 0.9444\n",
      "Epoch 76/150\n",
      "90/90 [==============================] - 0s 228us/step - loss: 0.4207 - accuracy: 0.8778 - val_loss: 0.4243 - val_accuracy: 0.9167\n",
      "Epoch 77/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.4169 - accuracy: 0.8778 - val_loss: 0.4195 - val_accuracy: 0.9444\n",
      "Epoch 78/150\n",
      "90/90 [==============================] - 0s 248us/step - loss: 0.4133 - accuracy: 0.9000 - val_loss: 0.4155 - val_accuracy: 0.9722\n",
      "Epoch 79/150\n",
      "90/90 [==============================] - 0s 255us/step - loss: 0.4094 - accuracy: 0.9000 - val_loss: 0.4110 - val_accuracy: 0.9444\n",
      "Epoch 80/150\n",
      "90/90 [==============================] - 0s 256us/step - loss: 0.4061 - accuracy: 0.8889 - val_loss: 0.4070 - val_accuracy: 0.9722\n",
      "Epoch 81/150\n",
      "90/90 [==============================] - 0s 238us/step - loss: 0.4019 - accuracy: 0.9111 - val_loss: 0.4023 - val_accuracy: 0.9722\n",
      "Epoch 82/150\n",
      "90/90 [==============================] - 0s 247us/step - loss: 0.3981 - accuracy: 0.9000 - val_loss: 0.3978 - val_accuracy: 0.9722\n",
      "Epoch 83/150\n",
      "90/90 [==============================] - 0s 244us/step - loss: 0.3942 - accuracy: 0.9111 - val_loss: 0.3933 - val_accuracy: 0.9722\n",
      "Epoch 84/150\n",
      "90/90 [==============================] - 0s 237us/step - loss: 0.3914 - accuracy: 0.9000 - val_loss: 0.3894 - val_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "90/90 [==============================] - 0s 236us/step - loss: 0.3873 - accuracy: 0.9111 - val_loss: 0.3844 - val_accuracy: 0.9722\n",
      "Epoch 86/150\n",
      "90/90 [==============================] - 0s 244us/step - loss: 0.3827 - accuracy: 0.9111 - val_loss: 0.3800 - val_accuracy: 0.9722\n",
      "Epoch 87/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 0.3804 - accuracy: 0.9111 - val_loss: 0.3765 - val_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "90/90 [==============================] - 0s 235us/step - loss: 0.3750 - accuracy: 0.9111 - val_loss: 0.3709 - val_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "90/90 [==============================] - 0s 227us/step - loss: 0.3709 - accuracy: 0.9222 - val_loss: 0.3663 - val_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "90/90 [==============================] - 0s 233us/step - loss: 0.3670 - accuracy: 0.9222 - val_loss: 0.3618 - val_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "90/90 [==============================] - 0s 232us/step - loss: 0.3633 - accuracy: 0.9111 - val_loss: 0.3573 - val_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "90/90 [==============================] - 0s 227us/step - loss: 0.3593 - accuracy: 0.9111 - val_loss: 0.3539 - val_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "90/90 [==============================] - 0s 227us/step - loss: 0.3551 - accuracy: 0.9111 - val_loss: 0.3485 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "90/90 [==============================] - 0s 236us/step - loss: 0.3510 - accuracy: 0.9111 - val_loss: 0.3441 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.3506 - accuracy: 0.9222 - val_loss: 0.3388 - val_accuracy: 0.9722\n",
      "Epoch 96/150\n",
      "90/90 [==============================] - 0s 252us/step - loss: 0.3444 - accuracy: 0.9222 - val_loss: 0.3367 - val_accuracy: 0.9722\n",
      "Epoch 97/150\n",
      "90/90 [==============================] - 0s 240us/step - loss: 0.3404 - accuracy: 0.9222 - val_loss: 0.3309 - val_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "90/90 [==============================] - 0s 234us/step - loss: 0.3366 - accuracy: 0.9111 - val_loss: 0.3291 - val_accuracy: 0.9722\n",
      "Epoch 99/150\n",
      "90/90 [==============================] - 0s 248us/step - loss: 0.3339 - accuracy: 0.9222 - val_loss: 0.3212 - val_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "90/90 [==============================] - 0s 255us/step - loss: 0.3277 - accuracy: 0.9222 - val_loss: 0.3171 - val_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "90/90 [==============================] - 0s 246us/step - loss: 0.3246 - accuracy: 0.9222 - val_loss: 0.3155 - val_accuracy: 0.9722\n",
      "Epoch 102/150\n",
      "90/90 [==============================] - 0s 237us/step - loss: 0.3211 - accuracy: 0.9333 - val_loss: 0.3100 - val_accuracy: 0.9722\n",
      "Epoch 103/150\n",
      "90/90 [==============================] - 0s 233us/step - loss: 0.3162 - accuracy: 0.9222 - val_loss: 0.3048 - val_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "90/90 [==============================] - 0s 235us/step - loss: 0.3134 - accuracy: 0.9222 - val_loss: 0.2997 - val_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "90/90 [==============================] - 0s 231us/step - loss: 0.3107 - accuracy: 0.9333 - val_loss: 0.2987 - val_accuracy: 0.9722\n",
      "Epoch 106/150\n",
      "90/90 [==============================] - 0s 233us/step - loss: 0.3073 - accuracy: 0.9111 - val_loss: 0.2913 - val_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "90/90 [==============================] - 0s 257us/step - loss: 0.3025 - accuracy: 0.9333 - val_loss: 0.2885 - val_accuracy: 0.9722\n",
      "Epoch 108/150\n",
      "90/90 [==============================] - 0s 247us/step - loss: 0.2987 - accuracy: 0.9333 - val_loss: 0.2841 - val_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.2980 - accuracy: 0.9111 - val_loss: 0.2787 - val_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "90/90 [==============================] - 0s 238us/step - loss: 0.2968 - accuracy: 0.9444 - val_loss: 0.2808 - val_accuracy: 0.9722\n",
      "Epoch 111/150\n",
      "90/90 [==============================] - 0s 239us/step - loss: 0.2904 - accuracy: 0.9222 - val_loss: 0.2708 - val_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.2853 - accuracy: 0.9333 - val_loss: 0.2684 - val_accuracy: 0.9722\n",
      "Epoch 113/150\n",
      "90/90 [==============================] - 0s 263us/step - loss: 0.2816 - accuracy: 0.9333 - val_loss: 0.2661 - val_accuracy: 0.9722\n",
      "Epoch 114/150\n",
      "90/90 [==============================] - 0s 258us/step - loss: 0.2770 - accuracy: 0.9333 - val_loss: 0.2593 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "90/90 [==============================] - 0s 240us/step - loss: 0.2743 - accuracy: 0.9333 - val_loss: 0.2561 - val_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "90/90 [==============================] - 0s 236us/step - loss: 0.2711 - accuracy: 0.9333 - val_loss: 0.2529 - val_accuracy: 0.9722\n",
      "Epoch 117/150\n",
      "90/90 [==============================] - 0s 231us/step - loss: 0.2718 - accuracy: 0.9333 - val_loss: 0.2480 - val_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "90/90 [==============================] - 0s 240us/step - loss: 0.2668 - accuracy: 0.9111 - val_loss: 0.2493 - val_accuracy: 0.9722\n",
      "Epoch 119/150\n",
      "90/90 [==============================] - 0s 238us/step - loss: 0.2611 - accuracy: 0.9556 - val_loss: 0.2423 - val_accuracy: 0.9722\n",
      "Epoch 120/150\n",
      "90/90 [==============================] - 0s 250us/step - loss: 0.2574 - accuracy: 0.9333 - val_loss: 0.2373 - val_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "90/90 [==============================] - 0s 261us/step - loss: 0.2551 - accuracy: 0.9333 - val_loss: 0.2345 - val_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "90/90 [==============================] - 0s 228us/step - loss: 0.2521 - accuracy: 0.9444 - val_loss: 0.2297 - val_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "90/90 [==============================] - 0s 232us/step - loss: 0.2488 - accuracy: 0.9444 - val_loss: 0.2268 - val_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "90/90 [==============================] - 0s 240us/step - loss: 0.2455 - accuracy: 0.9444 - val_loss: 0.2261 - val_accuracy: 0.9722\n",
      "Epoch 125/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 0.2443 - accuracy: 0.9333 - val_loss: 0.2198 - val_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "90/90 [==============================] - 0s 254us/step - loss: 0.2415 - accuracy: 0.9444 - val_loss: 0.2171 - val_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "90/90 [==============================] - 0s 234us/step - loss: 0.2375 - accuracy: 0.9556 - val_loss: 0.2169 - val_accuracy: 0.9722\n",
      "Epoch 128/150\n",
      "90/90 [==============================] - 0s 236us/step - loss: 0.2347 - accuracy: 0.9556 - val_loss: 0.2113 - val_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "90/90 [==============================] - 0s 232us/step - loss: 0.2369 - accuracy: 0.9333 - val_loss: 0.2067 - val_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "90/90 [==============================] - 0s 245us/step - loss: 0.2285 - accuracy: 0.9444 - val_loss: 0.2080 - val_accuracy: 0.9722\n",
      "Epoch 131/150\n",
      "90/90 [==============================] - 0s 226us/step - loss: 0.2315 - accuracy: 0.9444 - val_loss: 0.2058 - val_accuracy: 0.9722\n",
      "Epoch 132/150\n",
      "90/90 [==============================] - 0s 228us/step - loss: 0.2243 - accuracy: 0.9556 - val_loss: 0.1975 - val_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "90/90 [==============================] - 0s 231us/step - loss: 0.2231 - accuracy: 0.9444 - val_loss: 0.1947 - val_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "90/90 [==============================] - 0s 235us/step - loss: 0.2180 - accuracy: 0.9333 - val_loss: 0.1957 - val_accuracy: 0.9722\n",
      "Epoch 135/150\n",
      "90/90 [==============================] - 0s 250us/step - loss: 0.2190 - accuracy: 0.9444 - val_loss: 0.1913 - val_accuracy: 0.9722\n",
      "Epoch 136/150\n",
      "90/90 [==============================] - 0s 234us/step - loss: 0.2155 - accuracy: 0.9444 - val_loss: 0.1873 - val_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "90/90 [==============================] - 0s 237us/step - loss: 0.2120 - accuracy: 0.9556 - val_loss: 0.1865 - val_accuracy: 0.9722\n",
      "Epoch 138/150\n",
      "90/90 [==============================] - 0s 233us/step - loss: 0.2125 - accuracy: 0.9556 - val_loss: 0.1852 - val_accuracy: 0.9722\n",
      "Epoch 139/150\n",
      "90/90 [==============================] - 0s 245us/step - loss: 0.2067 - accuracy: 0.9556 - val_loss: 0.1788 - val_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "90/90 [==============================] - 0s 244us/step - loss: 0.2098 - accuracy: 0.9556 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.2054 - accuracy: 0.9333 - val_loss: 0.1825 - val_accuracy: 0.9722\n",
      "Epoch 142/150\n",
      "90/90 [==============================] - 0s 232us/step - loss: 0.2015 - accuracy: 0.9556 - val_loss: 0.1731 - val_accuracy: 0.9722\n",
      "Epoch 143/150\n",
      "90/90 [==============================] - 0s 235us/step - loss: 0.1977 - accuracy: 0.9556 - val_loss: 0.1689 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "90/90 [==============================] - 0s 257us/step - loss: 0.1981 - accuracy: 0.9444 - val_loss: 0.1665 - val_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "90/90 [==============================] - 0s 246us/step - loss: 0.1953 - accuracy: 0.9556 - val_loss: 0.1684 - val_accuracy: 0.9722\n",
      "Epoch 146/150\n",
      "90/90 [==============================] - 0s 230us/step - loss: 0.1929 - accuracy: 0.9556 - val_loss: 0.1646 - val_accuracy: 0.9722\n",
      "Epoch 147/150\n",
      "90/90 [==============================] - 0s 228us/step - loss: 0.1914 - accuracy: 0.9444 - val_loss: 0.1603 - val_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "90/90 [==============================] - 0s 241us/step - loss: 0.1892 - accuracy: 0.9556 - val_loss: 0.1605 - val_accuracy: 0.9722\n",
      "Epoch 149/150\n",
      "90/90 [==============================] - 0s 233us/step - loss: 0.1885 - accuracy: 0.9444 - val_loss: 0.1554 - val_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "90/90 [==============================] - 0s 236us/step - loss: 0.1859 - accuracy: 0.9556 - val_loss: 0.1544 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model2 = model_2()\n",
    "history2 = model2.fit(x_train, y_train, epochs = 150, batch_size=10, \n",
    "                   validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9c741ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 76us/step\n",
      "accuracy 100.0\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.evaluate(x_test, y_test)\n",
    "print(model2.metrics_names[1], score2[1]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
