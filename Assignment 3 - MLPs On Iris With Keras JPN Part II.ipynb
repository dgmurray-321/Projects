{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea838e1",
   "metadata": {},
   "source": [
    "## Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc21eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import keras as k \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from os import path\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50136f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_5824/98304411.py:2: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "tf.set_random_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9bdb11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Assignment 3 - MLPs On Iris With Keras JPN.ipynb'   Untitled.ipynb\r\n",
      " Iris.csv\t\t\t\t\t     Untitled1.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed4b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./Iris.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee62145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "(150, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af4838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0            5.1           3.5            1.4           0.2\n",
      "1            4.9           3.0            1.4           0.2\n",
      "2            4.7           3.2            1.3           0.2\n",
      "3            4.6           3.1            1.5           0.2\n",
      "4            5.0           3.6            1.4           0.2\n",
      "\n",
      "0    Iris-setosa\n",
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "Name: Species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns = ['Id', 'Species'], axis = 1)\n",
    "y = df['Species']\n",
    "\n",
    "print(x.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbfe4079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x training: (90, 4)\n",
      "\n",
      "y training: (90,)\n",
      "\n",
      "x test: (24, 4)\n",
      "\n",
      "y validation: (36,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size = .40, random_state=7)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val,y_val, test_size = .40, random_state = 7)\n",
    "\n",
    "print(\"x training:\", x_train.shape)\n",
    "print()\n",
    "print(\"y training:\",y_train.shape)\n",
    "print()\n",
    "print(\"x test:\",x_test.shape)\n",
    "print()\n",
    "print(\"y validation:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386fb2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "0            0                1               0\n",
      "1            0                1               0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train = lb.fit_transform(y_train)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns = lb.classes_)\n",
    "\n",
    "y_val = lb.transform(y_val)\n",
    "y_val = pd.DataFrame(y_val, columns = lb.classes_)\n",
    "\n",
    "y_test = lb.transform(y_test)\n",
    "y_test = pd.DataFrame(y_test, columns = lb.classes_)\n",
    "print(lb.classes_)\n",
    "print(y_test.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2aee2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e25c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim = 4, activation = 'relu'))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer = 'adam', \n",
    "                 metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f979d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 90 samples, validate on 36 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=8\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_MWAIT_HINTS=0\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEBUG=disabled\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='8'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2023-09-15 01:15:48.817086: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200205000 Hz\n",
      "2023-09-15 01:15:48.818832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560a037d3f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-15 01:15:48.818865: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-09-15 01:15:48.819070: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 5ms/step - loss: 1.8218 - accuracy: 0.3333 - val_loss: 1.5756 - val_accuracy: 0.3889\n",
      "Epoch 2/150\n",
      "90/90 [==============================] - 0s 234us/step - loss: 1.6464 - accuracy: 0.3333 - val_loss: 1.4124 - val_accuracy: 0.3889\n",
      "Epoch 3/150\n",
      "90/90 [==============================] - 0s 231us/step - loss: 1.5056 - accuracy: 0.3333 - val_loss: 1.2958 - val_accuracy: 0.3889\n",
      "Epoch 4/150\n",
      "90/90 [==============================] - 0s 225us/step - loss: 1.3975 - accuracy: 0.3333 - val_loss: 1.2190 - val_accuracy: 0.3889\n",
      "Epoch 5/150\n",
      "10/90 [==>...........................] - ETA: 0s - loss: 1.4412 - accuracy: 0.3000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5869 thread 0 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5869 thread 1 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5872 thread 2 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5873 thread 3 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5875 thread 5 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5874 thread 4 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5877 thread 7 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5876 thread 6 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5878 thread 8 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5870 thread 9 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5879 thread 10 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5881 thread 12 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5882 thread 13 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5883 thread 14 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5880 thread 11 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5885 thread 16 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 5824 tid 5884 thread 15 bound to OS proc set 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 222us/step - loss: 1.3217 - accuracy: 0.3444 - val_loss: 1.1538 - val_accuracy: 0.3889\n",
      "Epoch 6/150\n",
      "90/90 [==============================] - 0s 229us/step - loss: 1.2416 - accuracy: 0.3444 - val_loss: 1.1000 - val_accuracy: 0.3889\n",
      "Epoch 7/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 1.1777 - accuracy: 0.3444 - val_loss: 1.0450 - val_accuracy: 0.3889\n",
      "Epoch 8/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.1102 - accuracy: 0.3444 - val_loss: 0.9955 - val_accuracy: 0.3889\n",
      "Epoch 9/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 1.0516 - accuracy: 0.3444 - val_loss: 0.9492 - val_accuracy: 0.3889\n",
      "Epoch 10/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.9981 - accuracy: 0.3444 - val_loss: 0.9058 - val_accuracy: 0.3889\n",
      "Epoch 11/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.9464 - accuracy: 0.3444 - val_loss: 0.8663 - val_accuracy: 0.3889\n",
      "Epoch 12/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.8989 - accuracy: 0.3444 - val_loss: 0.8307 - val_accuracy: 0.3889\n",
      "Epoch 13/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.8588 - accuracy: 0.3444 - val_loss: 0.7986 - val_accuracy: 0.3889\n",
      "Epoch 14/150\n",
      "90/90 [==============================] - 0s 218us/step - loss: 0.8212 - accuracy: 0.3556 - val_loss: 0.7692 - val_accuracy: 0.3889\n",
      "Epoch 15/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.7914 - accuracy: 0.4222 - val_loss: 0.7443 - val_accuracy: 0.5556\n",
      "Epoch 16/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.7637 - accuracy: 0.6222 - val_loss: 0.7264 - val_accuracy: 0.6389\n",
      "Epoch 17/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.7377 - accuracy: 0.6667 - val_loss: 0.7099 - val_accuracy: 0.6667\n",
      "Epoch 18/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.7199 - accuracy: 0.7000 - val_loss: 0.6939 - val_accuracy: 0.6667\n",
      "Epoch 19/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.7042 - accuracy: 0.6889 - val_loss: 0.6804 - val_accuracy: 0.6944\n",
      "Epoch 20/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.6865 - accuracy: 0.6889 - val_loss: 0.6692 - val_accuracy: 0.6944\n",
      "Epoch 21/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.6746 - accuracy: 0.7000 - val_loss: 0.6584 - val_accuracy: 0.6944\n",
      "Epoch 22/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.6616 - accuracy: 0.7000 - val_loss: 0.6482 - val_accuracy: 0.6944\n",
      "Epoch 23/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.6505 - accuracy: 0.7111 - val_loss: 0.6391 - val_accuracy: 0.6944\n",
      "Epoch 24/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.6399 - accuracy: 0.7111 - val_loss: 0.6293 - val_accuracy: 0.6944\n",
      "Epoch 25/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.6306 - accuracy: 0.7000 - val_loss: 0.6211 - val_accuracy: 0.6944\n",
      "Epoch 26/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.6214 - accuracy: 0.7111 - val_loss: 0.6136 - val_accuracy: 0.7222\n",
      "Epoch 27/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.6145 - accuracy: 0.7000 - val_loss: 0.6050 - val_accuracy: 0.6944\n",
      "Epoch 28/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.6049 - accuracy: 0.7000 - val_loss: 0.5981 - val_accuracy: 0.6944\n",
      "Epoch 29/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.5960 - accuracy: 0.7222 - val_loss: 0.5920 - val_accuracy: 0.7222\n",
      "Epoch 30/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.5893 - accuracy: 0.7333 - val_loss: 0.5852 - val_accuracy: 0.7222\n",
      "Epoch 31/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.5821 - accuracy: 0.7333 - val_loss: 0.5784 - val_accuracy: 0.7222\n",
      "Epoch 32/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.5767 - accuracy: 0.7333 - val_loss: 0.5735 - val_accuracy: 0.7222\n",
      "Epoch 33/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.5721 - accuracy: 0.7111 - val_loss: 0.5657 - val_accuracy: 0.6944\n",
      "Epoch 34/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.5647 - accuracy: 0.7000 - val_loss: 0.5602 - val_accuracy: 0.6944\n",
      "Epoch 35/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.5586 - accuracy: 0.7333 - val_loss: 0.5571 - val_accuracy: 0.7500\n",
      "Epoch 36/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.5528 - accuracy: 0.7444 - val_loss: 0.5502 - val_accuracy: 0.7222\n",
      "Epoch 37/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.5469 - accuracy: 0.7444 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 38/150\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.5405 - accuracy: 0.7444 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 39/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.5362 - accuracy: 0.7444 - val_loss: 0.5350 - val_accuracy: 0.7222\n",
      "Epoch 40/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.5301 - accuracy: 0.7444 - val_loss: 0.5304 - val_accuracy: 0.7222\n",
      "Epoch 41/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.5288 - accuracy: 0.7556 - val_loss: 0.5277 - val_accuracy: 0.8333\n",
      "Epoch 42/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.5231 - accuracy: 0.7444 - val_loss: 0.5209 - val_accuracy: 0.7222\n",
      "Epoch 43/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.5170 - accuracy: 0.7444 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 44/150\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.5122 - accuracy: 0.7444 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
      "Epoch 45/150\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.5071 - accuracy: 0.7556 - val_loss: 0.5094 - val_accuracy: 0.7778\n",
      "Epoch 46/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.5043 - accuracy: 0.7889 - val_loss: 0.5057 - val_accuracy: 0.8056\n",
      "Epoch 47/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.5000 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 48/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.4956 - accuracy: 0.7667 - val_loss: 0.4978 - val_accuracy: 0.8056\n",
      "Epoch 49/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.4915 - accuracy: 0.8111 - val_loss: 0.4949 - val_accuracy: 0.8611\n",
      "Epoch 50/150\n",
      "90/90 [==============================] - 0s 182us/step - loss: 0.4881 - accuracy: 0.7889 - val_loss: 0.4899 - val_accuracy: 0.8056\n",
      "Epoch 51/150\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.4837 - accuracy: 0.7778 - val_loss: 0.4862 - val_accuracy: 0.8056\n",
      "Epoch 52/150\n",
      "90/90 [==============================] - 0s 178us/step - loss: 0.4804 - accuracy: 0.7778 - val_loss: 0.4826 - val_accuracy: 0.8056\n",
      "Epoch 53/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.4786 - accuracy: 0.7667 - val_loss: 0.4793 - val_accuracy: 0.8056\n",
      "Epoch 54/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.4747 - accuracy: 0.8778 - val_loss: 0.4801 - val_accuracy: 0.9167\n",
      "Epoch 55/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.4704 - accuracy: 0.9000 - val_loss: 0.4754 - val_accuracy: 0.9167\n",
      "Epoch 56/150\n",
      "90/90 [==============================] - 0s 179us/step - loss: 0.4684 - accuracy: 0.8111 - val_loss: 0.4688 - val_accuracy: 0.8056\n",
      "Epoch 57/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4654 - val_accuracy: 0.7778\n",
      "Epoch 58/150\n",
      "90/90 [==============================] - 0s 182us/step - loss: 0.4634 - accuracy: 0.8444 - val_loss: 0.4653 - val_accuracy: 0.9167\n",
      "Epoch 59/150\n",
      "90/90 [==============================] - 0s 178us/step - loss: 0.4568 - accuracy: 0.9111 - val_loss: 0.4619 - val_accuracy: 0.9167\n",
      "Epoch 60/150\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.4539 - accuracy: 0.8778 - val_loss: 0.4577 - val_accuracy: 0.9167\n",
      "Epoch 61/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.4509 - accuracy: 0.8111 - val_loss: 0.4532 - val_accuracy: 0.8056\n",
      "Epoch 62/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.4524 - accuracy: 0.8556 - val_loss: 0.4530 - val_accuracy: 0.9167\n",
      "Epoch 63/150\n",
      "90/90 [==============================] - 0s 206us/step - loss: 0.4447 - accuracy: 0.9000 - val_loss: 0.4482 - val_accuracy: 0.9167\n",
      "Epoch 64/150\n",
      "90/90 [==============================] - 0s 208us/step - loss: 0.4459 - accuracy: 0.8000 - val_loss: 0.4444 - val_accuracy: 0.8056\n",
      "Epoch 65/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.4402 - accuracy: 0.8444 - val_loss: 0.4437 - val_accuracy: 0.9167\n",
      "Epoch 66/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.4352 - accuracy: 0.9111 - val_loss: 0.4410 - val_accuracy: 0.9167\n",
      "Epoch 67/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.4328 - accuracy: 0.9000 - val_loss: 0.4372 - val_accuracy: 0.9167\n",
      "Epoch 68/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.4304 - accuracy: 0.9000 - val_loss: 0.4354 - val_accuracy: 0.9167\n",
      "Epoch 69/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.4285 - accuracy: 0.8778 - val_loss: 0.4310 - val_accuracy: 0.8889\n",
      "Epoch 70/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.4260 - accuracy: 0.8889 - val_loss: 0.4309 - val_accuracy: 0.9722\n",
      "Epoch 71/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.4229 - accuracy: 0.9111 - val_loss: 0.4262 - val_accuracy: 0.9167\n",
      "Epoch 72/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.4208 - accuracy: 0.9000 - val_loss: 0.4256 - val_accuracy: 0.9722\n",
      "Epoch 73/150\n",
      "90/90 [==============================] - 0s 220us/step - loss: 0.4169 - accuracy: 0.9000 - val_loss: 0.4218 - val_accuracy: 0.9167\n",
      "Epoch 74/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.4140 - accuracy: 0.9111 - val_loss: 0.4192 - val_accuracy: 0.9167\n",
      "Epoch 75/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.4125 - accuracy: 0.9222 - val_loss: 0.4172 - val_accuracy: 0.9444\n",
      "Epoch 76/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.4090 - accuracy: 0.9111 - val_loss: 0.4138 - val_accuracy: 0.9167\n",
      "Epoch 77/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.4111 - accuracy: 0.8778 - val_loss: 0.4107 - val_accuracy: 0.8333\n",
      "Epoch 78/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.4039 - accuracy: 0.8667 - val_loss: 0.4090 - val_accuracy: 0.9167\n",
      "Epoch 79/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.4038 - accuracy: 0.9222 - val_loss: 0.4127 - val_accuracy: 0.9722\n",
      "Epoch 80/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.4016 - accuracy: 0.9444 - val_loss: 0.4054 - val_accuracy: 0.9722\n",
      "Epoch 81/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.4025 - accuracy: 0.8889 - val_loss: 0.4013 - val_accuracy: 0.9167\n",
      "Epoch 82/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.3935 - accuracy: 0.8889 - val_loss: 0.4004 - val_accuracy: 0.9722\n",
      "Epoch 83/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.3920 - accuracy: 0.9556 - val_loss: 0.4005 - val_accuracy: 0.9722\n",
      "Epoch 84/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.3907 - accuracy: 0.9556 - val_loss: 0.3983 - val_accuracy: 0.9722\n",
      "Epoch 85/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.3890 - accuracy: 0.9333 - val_loss: 0.3932 - val_accuracy: 0.9722\n",
      "Epoch 86/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.3870 - accuracy: 0.9333 - val_loss: 0.3923 - val_accuracy: 0.9722\n",
      "Epoch 87/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.3836 - accuracy: 0.9111 - val_loss: 0.3880 - val_accuracy: 0.9167\n",
      "Epoch 88/150\n",
      "90/90 [==============================] - 0s 179us/step - loss: 0.3805 - accuracy: 0.9000 - val_loss: 0.3861 - val_accuracy: 0.9444\n",
      "Epoch 89/150\n",
      "90/90 [==============================] - 0s 178us/step - loss: 0.3788 - accuracy: 0.9000 - val_loss: 0.3845 - val_accuracy: 0.9722\n",
      "Epoch 90/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.3778 - accuracy: 0.9556 - val_loss: 0.3856 - val_accuracy: 0.9722\n",
      "Epoch 91/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.3760 - accuracy: 0.9556 - val_loss: 0.3806 - val_accuracy: 0.9722\n",
      "Epoch 92/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.3747 - accuracy: 0.9111 - val_loss: 0.3769 - val_accuracy: 0.9444\n",
      "Epoch 93/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.3702 - accuracy: 0.9111 - val_loss: 0.3768 - val_accuracy: 0.9722\n",
      "Epoch 94/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.3683 - accuracy: 0.9556 - val_loss: 0.3760 - val_accuracy: 0.9722\n",
      "Epoch 95/150\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.3668 - accuracy: 0.9556 - val_loss: 0.3719 - val_accuracy: 0.9722\n",
      "Epoch 96/150\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.3632 - accuracy: 0.9556 - val_loss: 0.3692 - val_accuracy: 0.9722\n",
      "Epoch 97/150\n",
      "90/90 [==============================] - 0s 182us/step - loss: 0.3618 - accuracy: 0.9444 - val_loss: 0.3674 - val_accuracy: 0.9722\n",
      "Epoch 98/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.3604 - accuracy: 0.9667 - val_loss: 0.3673 - val_accuracy: 0.9722\n",
      "Epoch 99/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.3570 - accuracy: 0.9556 - val_loss: 0.3633 - val_accuracy: 0.9722\n",
      "Epoch 100/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.3575 - accuracy: 0.9222 - val_loss: 0.3604 - val_accuracy: 0.9722\n",
      "Epoch 101/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.3596 - accuracy: 0.9444 - val_loss: 0.3617 - val_accuracy: 0.9722\n",
      "Epoch 102/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.3511 - accuracy: 0.9778 - val_loss: 0.3592 - val_accuracy: 0.9722\n",
      "Epoch 103/150\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.3484 - accuracy: 0.9778 - val_loss: 0.3549 - val_accuracy: 0.9722\n",
      "Epoch 104/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.3473 - accuracy: 0.9444 - val_loss: 0.3528 - val_accuracy: 0.9722\n",
      "Epoch 105/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.3462 - accuracy: 0.9444 - val_loss: 0.3506 - val_accuracy: 0.9722\n",
      "Epoch 106/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.3421 - accuracy: 0.9556 - val_loss: 0.3501 - val_accuracy: 0.9722\n",
      "Epoch 107/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.3409 - accuracy: 0.9778 - val_loss: 0.3500 - val_accuracy: 0.9722\n",
      "Epoch 108/150\n",
      "90/90 [==============================] - 0s 182us/step - loss: 0.3417 - accuracy: 0.9778 - val_loss: 0.3453 - val_accuracy: 0.9722\n",
      "Epoch 109/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.3371 - accuracy: 0.9667 - val_loss: 0.3443 - val_accuracy: 0.9722\n",
      "Epoch 110/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.3353 - accuracy: 0.9778 - val_loss: 0.3429 - val_accuracy: 0.9722\n",
      "Epoch 111/150\n",
      "90/90 [==============================] - 0s 179us/step - loss: 0.3368 - accuracy: 0.9667 - val_loss: 0.3390 - val_accuracy: 0.9722\n",
      "Epoch 112/150\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.3344 - accuracy: 0.9778 - val_loss: 0.3419 - val_accuracy: 0.9722\n",
      "Epoch 113/150\n",
      "90/90 [==============================] - 0s 179us/step - loss: 0.3301 - accuracy: 0.9778 - val_loss: 0.3373 - val_accuracy: 0.9722\n",
      "Epoch 114/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.3276 - accuracy: 0.9778 - val_loss: 0.3336 - val_accuracy: 0.9722\n",
      "Epoch 115/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.3256 - accuracy: 0.9667 - val_loss: 0.3319 - val_accuracy: 0.9722\n",
      "Epoch 116/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.3241 - accuracy: 0.9778 - val_loss: 0.3304 - val_accuracy: 0.9722\n",
      "Epoch 117/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.3235 - accuracy: 0.9778 - val_loss: 0.3307 - val_accuracy: 0.9722\n",
      "Epoch 118/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.3218 - accuracy: 0.9778 - val_loss: 0.3276 - val_accuracy: 0.9722\n",
      "Epoch 119/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.3181 - accuracy: 0.9778 - val_loss: 0.3253 - val_accuracy: 0.9722\n",
      "Epoch 120/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.3167 - accuracy: 0.9778 - val_loss: 0.3234 - val_accuracy: 0.9722\n",
      "Epoch 121/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.3164 - accuracy: 0.9556 - val_loss: 0.3204 - val_accuracy: 0.9722\n",
      "Epoch 122/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.3139 - accuracy: 0.9778 - val_loss: 0.3196 - val_accuracy: 0.9722\n",
      "Epoch 123/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.3120 - accuracy: 0.9778 - val_loss: 0.3178 - val_accuracy: 0.9722\n",
      "Epoch 124/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.3115 - accuracy: 0.9778 - val_loss: 0.3199 - val_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.3094 - accuracy: 0.9778 - val_loss: 0.3178 - val_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.3044 - accuracy: 0.9778 - val_loss: 0.3122 - val_accuracy: 0.9722\n",
      "Epoch 127/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.3054 - accuracy: 0.9667 - val_loss: 0.3097 - val_accuracy: 0.9722\n",
      "Epoch 128/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.3034 - accuracy: 0.9778 - val_loss: 0.3089 - val_accuracy: 0.9722\n",
      "Epoch 129/150\n",
      "90/90 [==============================] - 0s 179us/step - loss: 0.3004 - accuracy: 0.9778 - val_loss: 0.3073 - val_accuracy: 0.9722\n",
      "Epoch 130/150\n",
      "90/90 [==============================] - 0s 179us/step - loss: 0.2986 - accuracy: 0.9778 - val_loss: 0.3056 - val_accuracy: 0.9722\n",
      "Epoch 131/150\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.2968 - accuracy: 0.9778 - val_loss: 0.3057 - val_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.2953 - accuracy: 0.9778 - val_loss: 0.3034 - val_accuracy: 0.9722\n",
      "Epoch 133/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.2952 - accuracy: 0.9778 - val_loss: 0.3029 - val_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.2921 - accuracy: 0.9778 - val_loss: 0.2996 - val_accuracy: 0.9722\n",
      "Epoch 135/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.2935 - accuracy: 0.9778 - val_loss: 0.2960 - val_accuracy: 0.9722\n",
      "Epoch 136/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 0.2903 - accuracy: 0.9778 - val_loss: 0.2944 - val_accuracy: 0.9722\n",
      "Epoch 137/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.2871 - accuracy: 0.9778 - val_loss: 0.2967 - val_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.2885 - accuracy: 0.9778 - val_loss: 0.2964 - val_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.2855 - accuracy: 0.9778 - val_loss: 0.2902 - val_accuracy: 0.9722\n",
      "Epoch 140/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.2828 - accuracy: 0.9778 - val_loss: 0.2879 - val_accuracy: 0.9722\n",
      "Epoch 141/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.2848 - accuracy: 0.9778 - val_loss: 0.2904 - val_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.2799 - accuracy: 0.9778 - val_loss: 0.2851 - val_accuracy: 0.9722\n",
      "Epoch 143/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.2774 - accuracy: 0.9778 - val_loss: 0.2846 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.2766 - accuracy: 0.9778 - val_loss: 0.2817 - val_accuracy: 0.9722\n",
      "Epoch 145/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.2758 - accuracy: 0.9778 - val_loss: 0.2830 - val_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.2724 - accuracy: 0.9778 - val_loss: 0.2801 - val_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.2709 - accuracy: 0.9778 - val_loss: 0.2780 - val_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.2695 - accuracy: 0.9778 - val_loss: 0.2763 - val_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.2674 - accuracy: 0.9778 - val_loss: 0.2746 - val_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.2662 - accuracy: 0.9778 - val_loss: 0.2732 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = model1()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 150, batch_size=10, \n",
    "                   validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02fc1a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 138us/step\n",
      "accuracy 91.66666865348816\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print(model.metrics_names[1], score[1]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
