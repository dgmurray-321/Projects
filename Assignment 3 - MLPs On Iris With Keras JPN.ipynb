{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0db2015",
   "metadata": {},
   "source": [
    "## Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc21eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import keras as k \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from os import path\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50136f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_11750/98304411.py:2: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "tf.set_random_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9bdb11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Assignment 3 Part 2.ipynb'   Iris.csv\t Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed4b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./Iris.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee62145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "(150, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af4838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0            5.1           3.5            1.4           0.2\n",
      "1            4.9           3.0            1.4           0.2\n",
      "2            4.7           3.2            1.3           0.2\n",
      "3            4.6           3.1            1.5           0.2\n",
      "4            5.0           3.6            1.4           0.2\n",
      "\n",
      "0    Iris-setosa\n",
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "Name: Species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns = ['Id', 'Species'], axis = 1)\n",
    "y = df['Species']\n",
    "\n",
    "print(x.head())\n",
    "print()\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbfe4079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x training: (90, 4)\n",
      "\n",
      "y training: (90,)\n",
      "\n",
      "x test: (24, 4)\n",
      "\n",
      "y validation: (36,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size = .40, random_state=7)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val,y_val, test_size = .40, random_state = 7)\n",
    "\n",
    "print(\"x training:\", x_train.shape)\n",
    "print()\n",
    "print(\"y training:\",y_train.shape)\n",
    "print()\n",
    "print(\"x test:\",x_test.shape)\n",
    "print()\n",
    "print(\"y validation:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386fb2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "   Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "0            0                1               0\n",
      "1            0                1               0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train = lb.fit_transform(y_train)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns = lb.classes_)\n",
    "\n",
    "y_val = lb.transform(y_val)\n",
    "y_val = pd.DataFrame(y_val, columns = lb.classes_)\n",
    "\n",
    "y_test = lb.transform(y_test)\n",
    "y_test = pd.DataFrame(y_test, columns = lb.classes_)\n",
    "print(lb.classes_)\n",
    "print(y_test.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2aee2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e25c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim = 4, activation = 'relu'))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                 optimizer = 'adam', \n",
    "                 metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f979d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 90 samples, validate on 36 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=8\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_MWAIT_HINTS=0\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEBUG=disabled\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='8'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2023-09-12 21:05:17.098293: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200205000 Hz\n",
      "2023-09-12 21:05:17.099412: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dd3a1c4330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-12 21:05:17.099449: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-09-12 21:05:17.099631: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 5ms/step - loss: 1.4473 - accuracy: 0.3222 - val_loss: 1.3942 - val_accuracy: 0.3056\n",
      "Epoch 2/150\n",
      "90/90 [==============================] - 0s 216us/step - loss: 1.3868 - accuracy: 0.3222 - val_loss: 1.3397 - val_accuracy: 0.3056\n",
      "Epoch 3/150\n",
      "90/90 [==============================] - 0s 218us/step - loss: 1.3326 - accuracy: 0.3222 - val_loss: 1.2919 - val_accuracy: 0.3056\n",
      "Epoch 4/150\n",
      "90/90 [==============================] - 0s 231us/step - loss: 1.2884 - accuracy: 0.3222 - val_loss: 1.2499 - val_accuracy: 0.3056\n",
      "Epoch 5/150\n",
      "90/90 [==============================] - 0s 222us/step - loss: 1.2502 - accuracy: 0.3222 - val_loss: 1.2148 - val_accuracy: 0.3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11797 thread 0 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11797 thread 1 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11799 thread 2 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11800 thread 3 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11802 thread 5 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11801 thread 4 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11803 thread 6 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11804 thread 7 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11805 thread 8 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11796 thread 9 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11808 thread 12 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11810 thread 14 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11807 thread 11 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11806 thread 10 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11809 thread 13 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11812 thread 16 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 11750 tid 11811 thread 15 bound to OS proc set 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 1.2156 - accuracy: 0.3222 - val_loss: 1.1840 - val_accuracy: 0.3056\n",
      "Epoch 7/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.1876 - accuracy: 0.3222 - val_loss: 1.1572 - val_accuracy: 0.3056\n",
      "Epoch 8/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 1.1633 - accuracy: 0.3222 - val_loss: 1.1326 - val_accuracy: 0.3056\n",
      "Epoch 9/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 1.1400 - accuracy: 0.3222 - val_loss: 1.1122 - val_accuracy: 0.3056\n",
      "Epoch 10/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 1.1216 - accuracy: 0.3222 - val_loss: 1.0930 - val_accuracy: 0.3056\n",
      "Epoch 11/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 1.1044 - accuracy: 0.3222 - val_loss: 1.0754 - val_accuracy: 0.3056\n",
      "Epoch 12/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 1.0880 - accuracy: 0.3222 - val_loss: 1.0598 - val_accuracy: 0.3056\n",
      "Epoch 13/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 1.0733 - accuracy: 0.3222 - val_loss: 1.0453 - val_accuracy: 0.3056\n",
      "Epoch 14/150\n",
      "90/90 [==============================] - 0s 216us/step - loss: 1.0597 - accuracy: 0.3222 - val_loss: 1.0320 - val_accuracy: 0.3056\n",
      "Epoch 15/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 1.0483 - accuracy: 0.3222 - val_loss: 1.0178 - val_accuracy: 0.3056\n",
      "Epoch 16/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.0336 - accuracy: 0.3222 - val_loss: 1.0064 - val_accuracy: 0.3056\n",
      "Epoch 17/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 1.0231 - accuracy: 0.3222 - val_loss: 0.9939 - val_accuracy: 0.3056\n",
      "Epoch 18/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 1.0120 - accuracy: 0.3222 - val_loss: 0.9829 - val_accuracy: 0.3056\n",
      "Epoch 19/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 1.0019 - accuracy: 0.3333 - val_loss: 0.9714 - val_accuracy: 0.3333\n",
      "Epoch 20/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.9913 - accuracy: 0.3333 - val_loss: 0.9605 - val_accuracy: 0.3333\n",
      "Epoch 21/150\n",
      "90/90 [==============================] - 0s 226us/step - loss: 0.9819 - accuracy: 0.3333 - val_loss: 0.9507 - val_accuracy: 0.3611\n",
      "Epoch 22/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.9716 - accuracy: 0.3222 - val_loss: 0.9405 - val_accuracy: 0.4167\n",
      "Epoch 23/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.9623 - accuracy: 0.3556 - val_loss: 0.9308 - val_accuracy: 0.4722\n",
      "Epoch 24/150\n",
      "90/90 [==============================] - 0s 206us/step - loss: 0.9527 - accuracy: 0.4000 - val_loss: 0.9208 - val_accuracy: 0.5556\n",
      "Epoch 25/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.9436 - accuracy: 0.4667 - val_loss: 0.9111 - val_accuracy: 0.6667\n",
      "Epoch 26/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.9345 - accuracy: 0.5444 - val_loss: 0.9027 - val_accuracy: 0.7500\n",
      "Epoch 27/150\n",
      "90/90 [==============================] - 0s 222us/step - loss: 0.9257 - accuracy: 0.6333 - val_loss: 0.8936 - val_accuracy: 0.7778\n",
      "Epoch 28/150\n",
      "90/90 [==============================] - 0s 210us/step - loss: 0.9169 - accuracy: 0.6889 - val_loss: 0.8856 - val_accuracy: 0.8333\n",
      "Epoch 29/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.9079 - accuracy: 0.7222 - val_loss: 0.8765 - val_accuracy: 0.7778\n",
      "Epoch 30/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.8995 - accuracy: 0.7000 - val_loss: 0.8683 - val_accuracy: 0.8056\n",
      "Epoch 31/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.8912 - accuracy: 0.7111 - val_loss: 0.8598 - val_accuracy: 0.7500\n",
      "Epoch 32/150\n",
      "90/90 [==============================] - 0s 222us/step - loss: 0.8832 - accuracy: 0.7111 - val_loss: 0.8525 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.8756 - accuracy: 0.6889 - val_loss: 0.8439 - val_accuracy: 0.7222\n",
      "Epoch 34/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.8674 - accuracy: 0.6778 - val_loss: 0.8358 - val_accuracy: 0.7222\n",
      "Epoch 35/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.8592 - accuracy: 0.6556 - val_loss: 0.8285 - val_accuracy: 0.6944\n",
      "Epoch 36/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.8520 - accuracy: 0.6667 - val_loss: 0.8202 - val_accuracy: 0.6944\n",
      "Epoch 37/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.8440 - accuracy: 0.6667 - val_loss: 0.8131 - val_accuracy: 0.6944\n",
      "Epoch 38/150\n",
      "90/90 [==============================] - 0s 218us/step - loss: 0.8365 - accuracy: 0.6667 - val_loss: 0.8060 - val_accuracy: 0.6944\n",
      "Epoch 39/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.8294 - accuracy: 0.6778 - val_loss: 0.7986 - val_accuracy: 0.6944\n",
      "Epoch 40/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.8219 - accuracy: 0.6778 - val_loss: 0.7912 - val_accuracy: 0.6944\n",
      "Epoch 41/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.8148 - accuracy: 0.6778 - val_loss: 0.7842 - val_accuracy: 0.6944\n",
      "Epoch 42/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 0.8078 - accuracy: 0.6778 - val_loss: 0.7768 - val_accuracy: 0.6944\n",
      "Epoch 43/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.8004 - accuracy: 0.6778 - val_loss: 0.7700 - val_accuracy: 0.6944\n",
      "Epoch 44/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.7933 - accuracy: 0.6778 - val_loss: 0.7628 - val_accuracy: 0.6944\n",
      "Epoch 45/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.7860 - accuracy: 0.6889 - val_loss: 0.7560 - val_accuracy: 0.6944\n",
      "Epoch 46/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.7793 - accuracy: 0.6889 - val_loss: 0.7494 - val_accuracy: 0.6944\n",
      "Epoch 47/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.7720 - accuracy: 0.6889 - val_loss: 0.7424 - val_accuracy: 0.6944\n",
      "Epoch 48/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.7648 - accuracy: 0.6889 - val_loss: 0.7361 - val_accuracy: 0.6944\n",
      "Epoch 49/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.7578 - accuracy: 0.6889 - val_loss: 0.7295 - val_accuracy: 0.6944\n",
      "Epoch 50/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.7510 - accuracy: 0.6889 - val_loss: 0.7226 - val_accuracy: 0.6944\n",
      "Epoch 51/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.7441 - accuracy: 0.6889 - val_loss: 0.7161 - val_accuracy: 0.6944\n",
      "Epoch 52/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.7370 - accuracy: 0.6889 - val_loss: 0.7095 - val_accuracy: 0.6944\n",
      "Epoch 53/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.7303 - accuracy: 0.6889 - val_loss: 0.7028 - val_accuracy: 0.6944\n",
      "Epoch 54/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.7233 - accuracy: 0.6889 - val_loss: 0.6968 - val_accuracy: 0.6944\n",
      "Epoch 55/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.7162 - accuracy: 0.7000 - val_loss: 0.6903 - val_accuracy: 0.6944\n",
      "Epoch 56/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.7094 - accuracy: 0.7000 - val_loss: 0.6835 - val_accuracy: 0.6944\n",
      "Epoch 57/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.7024 - accuracy: 0.6889 - val_loss: 0.6768 - val_accuracy: 0.6944\n",
      "Epoch 58/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.6956 - accuracy: 0.7111 - val_loss: 0.6709 - val_accuracy: 0.6944\n",
      "Epoch 59/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.6885 - accuracy: 0.7111 - val_loss: 0.6648 - val_accuracy: 0.7222\n",
      "Epoch 60/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.6818 - accuracy: 0.7111 - val_loss: 0.6584 - val_accuracy: 0.7222\n",
      "Epoch 61/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.6749 - accuracy: 0.7111 - val_loss: 0.6518 - val_accuracy: 0.7222\n",
      "Epoch 62/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.6684 - accuracy: 0.7222 - val_loss: 0.6459 - val_accuracy: 0.7222\n",
      "Epoch 63/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.6614 - accuracy: 0.7222 - val_loss: 0.6395 - val_accuracy: 0.7222\n",
      "Epoch 64/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.6553 - accuracy: 0.7111 - val_loss: 0.6329 - val_accuracy: 0.7222\n",
      "Epoch 65/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.6484 - accuracy: 0.7222 - val_loss: 0.6272 - val_accuracy: 0.7500\n",
      "Epoch 66/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.6417 - accuracy: 0.7222 - val_loss: 0.6211 - val_accuracy: 0.7500\n",
      "Epoch 67/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.6352 - accuracy: 0.7333 - val_loss: 0.6154 - val_accuracy: 0.7500\n",
      "Epoch 68/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.6295 - accuracy: 0.7333 - val_loss: 0.6098 - val_accuracy: 0.7500\n",
      "Epoch 69/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.6229 - accuracy: 0.7333 - val_loss: 0.6036 - val_accuracy: 0.7500\n",
      "Epoch 70/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.6167 - accuracy: 0.7333 - val_loss: 0.5983 - val_accuracy: 0.7500\n",
      "Epoch 71/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.6107 - accuracy: 0.7444 - val_loss: 0.5926 - val_accuracy: 0.7500\n",
      "Epoch 72/150\n",
      "90/90 [==============================] - 0s 224us/step - loss: 0.6050 - accuracy: 0.7444 - val_loss: 0.5875 - val_accuracy: 0.7500\n",
      "Epoch 73/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.5986 - accuracy: 0.7556 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
      "Epoch 74/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.5929 - accuracy: 0.7556 - val_loss: 0.5765 - val_accuracy: 0.7500\n",
      "Epoch 75/150\n",
      "90/90 [==============================] - 0s 228us/step - loss: 0.5874 - accuracy: 0.7556 - val_loss: 0.5715 - val_accuracy: 0.7500\n",
      "Epoch 76/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.5821 - accuracy: 0.7556 - val_loss: 0.5663 - val_accuracy: 0.7500\n",
      "Epoch 77/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.5771 - accuracy: 0.7556 - val_loss: 0.5606 - val_accuracy: 0.7500\n",
      "Epoch 78/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.5711 - accuracy: 0.7556 - val_loss: 0.5558 - val_accuracy: 0.7500\n",
      "Epoch 79/150\n",
      "90/90 [==============================] - 0s 206us/step - loss: 0.5659 - accuracy: 0.7556 - val_loss: 0.5516 - val_accuracy: 0.7500\n",
      "Epoch 80/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.5609 - accuracy: 0.7778 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 81/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.5565 - accuracy: 0.7556 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
      "Epoch 82/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.5507 - accuracy: 0.7556 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
      "Epoch 83/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.5463 - accuracy: 0.7778 - val_loss: 0.5335 - val_accuracy: 0.7778\n",
      "Epoch 84/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.5417 - accuracy: 0.7778 - val_loss: 0.5294 - val_accuracy: 0.8056\n",
      "Epoch 85/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.5371 - accuracy: 0.7778 - val_loss: 0.5247 - val_accuracy: 0.8056\n",
      "Epoch 86/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.5333 - accuracy: 0.8000 - val_loss: 0.5211 - val_accuracy: 0.8333\n",
      "Epoch 87/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.5283 - accuracy: 0.7778 - val_loss: 0.5163 - val_accuracy: 0.8056\n",
      "Epoch 88/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.5238 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.8056\n",
      "Epoch 89/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.5199 - accuracy: 0.7778 - val_loss: 0.5083 - val_accuracy: 0.8056\n",
      "Epoch 90/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.5157 - accuracy: 0.7889 - val_loss: 0.5050 - val_accuracy: 0.8611\n",
      "Epoch 91/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.5121 - accuracy: 0.8111 - val_loss: 0.5012 - val_accuracy: 0.8611\n",
      "Epoch 92/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.5081 - accuracy: 0.7889 - val_loss: 0.4971 - val_accuracy: 0.8056\n",
      "Epoch 93/150\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.5040 - accuracy: 0.7889 - val_loss: 0.4939 - val_accuracy: 0.8611\n",
      "Epoch 94/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.5004 - accuracy: 0.8222 - val_loss: 0.4906 - val_accuracy: 0.8889\n",
      "Epoch 95/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.4969 - accuracy: 0.8222 - val_loss: 0.4870 - val_accuracy: 0.8611\n",
      "Epoch 96/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.4932 - accuracy: 0.8222 - val_loss: 0.4837 - val_accuracy: 0.8889\n",
      "Epoch 97/150\n",
      "90/90 [==============================] - 0s 179us/step - loss: 0.4898 - accuracy: 0.8222 - val_loss: 0.4804 - val_accuracy: 0.8889\n",
      "Epoch 98/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.4865 - accuracy: 0.8222 - val_loss: 0.4776 - val_accuracy: 0.8889\n",
      "Epoch 99/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.4830 - accuracy: 0.8222 - val_loss: 0.4741 - val_accuracy: 0.8889\n",
      "Epoch 100/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.4804 - accuracy: 0.8222 - val_loss: 0.4707 - val_accuracy: 0.8611\n",
      "Epoch 101/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.4780 - accuracy: 0.8333 - val_loss: 0.4683 - val_accuracy: 0.9167\n",
      "Epoch 102/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.4737 - accuracy: 0.8556 - val_loss: 0.4656 - val_accuracy: 0.9167\n",
      "Epoch 103/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.4704 - accuracy: 0.8778 - val_loss: 0.4624 - val_accuracy: 0.9167\n",
      "Epoch 104/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.4675 - accuracy: 0.8333 - val_loss: 0.4594 - val_accuracy: 0.9167\n",
      "Epoch 105/150\n",
      "90/90 [==============================] - 0s 217us/step - loss: 0.4651 - accuracy: 0.8333 - val_loss: 0.4563 - val_accuracy: 0.8889\n",
      "Epoch 106/150\n",
      "90/90 [==============================] - 0s 344us/step - loss: 0.4617 - accuracy: 0.8333 - val_loss: 0.4537 - val_accuracy: 0.8889\n",
      "Epoch 107/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.4590 - accuracy: 0.8444 - val_loss: 0.4514 - val_accuracy: 0.9167\n",
      "Epoch 108/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.4566 - accuracy: 0.8778 - val_loss: 0.4486 - val_accuracy: 0.9167\n",
      "Epoch 109/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 0.4535 - accuracy: 0.8778 - val_loss: 0.4463 - val_accuracy: 0.9167\n",
      "Epoch 110/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.4510 - accuracy: 0.8778 - val_loss: 0.4439 - val_accuracy: 0.9167\n",
      "Epoch 111/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.4494 - accuracy: 0.8778 - val_loss: 0.4408 - val_accuracy: 0.9167\n",
      "Epoch 112/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.4463 - accuracy: 0.8778 - val_loss: 0.4392 - val_accuracy: 0.9167\n",
      "Epoch 113/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.4434 - accuracy: 0.8778 - val_loss: 0.4367 - val_accuracy: 0.9167\n",
      "Epoch 114/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.4409 - accuracy: 0.8778 - val_loss: 0.4341 - val_accuracy: 0.9167\n",
      "Epoch 115/150\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.4383 - accuracy: 0.8889 - val_loss: 0.4317 - val_accuracy: 0.9167\n",
      "Epoch 116/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.4360 - accuracy: 0.8889 - val_loss: 0.4292 - val_accuracy: 0.9167\n",
      "Epoch 117/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.4340 - accuracy: 0.8889 - val_loss: 0.4273 - val_accuracy: 0.9167\n",
      "Epoch 118/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.4319 - accuracy: 0.8889 - val_loss: 0.4249 - val_accuracy: 0.9167\n",
      "Epoch 119/150\n",
      "90/90 [==============================] - 0s 191us/step - loss: 0.4291 - accuracy: 0.8889 - val_loss: 0.4229 - val_accuracy: 0.9167\n",
      "Epoch 120/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.4269 - accuracy: 0.9000 - val_loss: 0.4207 - val_accuracy: 0.9167\n",
      "Epoch 121/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.4254 - accuracy: 0.9000 - val_loss: 0.4179 - val_accuracy: 0.9167\n",
      "Epoch 122/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.4226 - accuracy: 0.8889 - val_loss: 0.4159 - val_accuracy: 0.9167\n",
      "Epoch 123/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.4205 - accuracy: 0.8889 - val_loss: 0.4138 - val_accuracy: 0.9167\n",
      "Epoch 124/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.4187 - accuracy: 0.9000 - val_loss: 0.4125 - val_accuracy: 0.9167\n",
      "Epoch 125/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.4170 - accuracy: 0.9000 - val_loss: 0.4111 - val_accuracy: 0.9722\n",
      "Epoch 126/150\n",
      "90/90 [==============================] - 0s 182us/step - loss: 0.4138 - accuracy: 0.9000 - val_loss: 0.4087 - val_accuracy: 0.9167\n",
      "Epoch 127/150\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.4124 - accuracy: 0.9111 - val_loss: 0.4059 - val_accuracy: 0.9167\n",
      "Epoch 128/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.4102 - accuracy: 0.9000 - val_loss: 0.4040 - val_accuracy: 0.9167\n",
      "Epoch 129/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.4079 - accuracy: 0.9111 - val_loss: 0.4019 - val_accuracy: 0.9167\n",
      "Epoch 130/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.4060 - accuracy: 0.9111 - val_loss: 0.3998 - val_accuracy: 0.9167\n",
      "Epoch 131/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.4040 - accuracy: 0.9111 - val_loss: 0.3983 - val_accuracy: 0.9167\n",
      "Epoch 132/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.4020 - accuracy: 0.9111 - val_loss: 0.3964 - val_accuracy: 0.9167\n",
      "Epoch 133/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.4010 - accuracy: 0.9000 - val_loss: 0.3952 - val_accuracy: 0.9722\n",
      "Epoch 134/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.3985 - accuracy: 0.9222 - val_loss: 0.3933 - val_accuracy: 0.9722\n",
      "Epoch 135/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.3970 - accuracy: 0.9000 - val_loss: 0.3907 - val_accuracy: 0.9167\n",
      "Epoch 136/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.3951 - accuracy: 0.9111 - val_loss: 0.3885 - val_accuracy: 0.9167\n",
      "Epoch 137/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.3927 - accuracy: 0.9111 - val_loss: 0.3872 - val_accuracy: 0.9722\n",
      "Epoch 138/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.3916 - accuracy: 0.9222 - val_loss: 0.3860 - val_accuracy: 0.9722\n",
      "Epoch 139/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 0.3895 - accuracy: 0.9222 - val_loss: 0.3838 - val_accuracy: 0.9722\n",
      "Epoch 140/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.3872 - accuracy: 0.9111 - val_loss: 0.3817 - val_accuracy: 0.9722\n",
      "Epoch 141/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.3867 - accuracy: 0.9333 - val_loss: 0.3809 - val_accuracy: 0.9722\n",
      "Epoch 142/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.3839 - accuracy: 0.9222 - val_loss: 0.3783 - val_accuracy: 0.9722\n",
      "Epoch 143/150\n",
      "90/90 [==============================] - 0s 182us/step - loss: 0.3819 - accuracy: 0.9222 - val_loss: 0.3767 - val_accuracy: 0.9722\n",
      "Epoch 144/150\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.3805 - accuracy: 0.9222 - val_loss: 0.3746 - val_accuracy: 0.9722\n",
      "Epoch 145/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.3791 - accuracy: 0.9222 - val_loss: 0.3735 - val_accuracy: 0.9722\n",
      "Epoch 146/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.3768 - accuracy: 0.9222 - val_loss: 0.3717 - val_accuracy: 0.9722\n",
      "Epoch 147/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.3752 - accuracy: 0.9333 - val_loss: 0.3701 - val_accuracy: 0.9722\n",
      "Epoch 148/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.3736 - accuracy: 0.9333 - val_loss: 0.3685 - val_accuracy: 0.9722\n",
      "Epoch 149/150\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.3715 - accuracy: 0.9333 - val_loss: 0.3667 - val_accuracy: 0.9722\n",
      "Epoch 150/150\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.3700 - accuracy: 0.9333 - val_loss: 0.3649 - val_accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "model = model1()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 150, batch_size=10, \n",
    "                   validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02fc1a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 43us/step\n",
      "accuracy 83.33333134651184\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print(model.metrics_names[1], score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa84d3f",
   "metadata": {},
   "source": [
    "## Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec80c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "def model_2():\n",
    "    input_layer = Input(shape=(4,))\n",
    "    hidden_layer = Dense(3, activation='relu')(input_layer)\n",
    "    output_layer = Dense(3, activation = 'softmax')(hidden_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ea12c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 36 samples\n",
      "Epoch 1/150\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.0783 - accuracy: 0.3222 - val_loss: 1.9299 - val_accuracy: 0.3056\n",
      "Epoch 2/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 1.9903 - accuracy: 0.3222 - val_loss: 1.8389 - val_accuracy: 0.3056\n",
      "Epoch 3/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 1.9091 - accuracy: 0.3222 - val_loss: 1.7655 - val_accuracy: 0.3056\n",
      "Epoch 4/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 1.8457 - accuracy: 0.3222 - val_loss: 1.7028 - val_accuracy: 0.3056\n",
      "Epoch 5/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.7879 - accuracy: 0.3222 - val_loss: 1.6513 - val_accuracy: 0.3056\n",
      "Epoch 6/150\n",
      "90/90 [==============================] - 0s 216us/step - loss: 1.7367 - accuracy: 0.3222 - val_loss: 1.6059 - val_accuracy: 0.3056\n",
      "Epoch 7/150\n",
      "90/90 [==============================] - 0s 222us/step - loss: 1.6912 - accuracy: 0.3222 - val_loss: 1.5629 - val_accuracy: 0.3056\n",
      "Epoch 8/150\n",
      "90/90 [==============================] - 0s 210us/step - loss: 1.6516 - accuracy: 0.3222 - val_loss: 1.5229 - val_accuracy: 0.3056\n",
      "Epoch 9/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 1.6108 - accuracy: 0.3222 - val_loss: 1.4866 - val_accuracy: 0.3056\n",
      "Epoch 10/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 1.5745 - accuracy: 0.3222 - val_loss: 1.4529 - val_accuracy: 0.2500\n",
      "Epoch 11/150\n",
      "90/90 [==============================] - 0s 210us/step - loss: 1.5393 - accuracy: 0.3222 - val_loss: 1.4164 - val_accuracy: 0.3333\n",
      "Epoch 12/150\n",
      "90/90 [==============================] - 0s 217us/step - loss: 1.5050 - accuracy: 0.3333 - val_loss: 1.3873 - val_accuracy: 0.3611\n",
      "Epoch 13/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 1.4738 - accuracy: 0.3222 - val_loss: 1.3599 - val_accuracy: 0.3889\n",
      "Epoch 14/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 1.4434 - accuracy: 0.3111 - val_loss: 1.3360 - val_accuracy: 0.4167\n",
      "Epoch 15/150\n",
      "90/90 [==============================] - 0s 217us/step - loss: 1.4144 - accuracy: 0.3222 - val_loss: 1.3162 - val_accuracy: 0.3889\n",
      "Epoch 16/150\n",
      "90/90 [==============================] - 0s 208us/step - loss: 1.3880 - accuracy: 0.3556 - val_loss: 1.2980 - val_accuracy: 0.3889\n",
      "Epoch 17/150\n",
      "90/90 [==============================] - 0s 217us/step - loss: 1.3685 - accuracy: 0.3667 - val_loss: 1.2807 - val_accuracy: 0.4444\n",
      "Epoch 18/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 1.3479 - accuracy: 0.3667 - val_loss: 1.2669 - val_accuracy: 0.4444\n",
      "Epoch 19/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 1.3318 - accuracy: 0.3444 - val_loss: 1.2549 - val_accuracy: 0.5000\n",
      "Epoch 20/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 1.3178 - accuracy: 0.3667 - val_loss: 1.2436 - val_accuracy: 0.5556\n",
      "Epoch 21/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 1.3013 - accuracy: 0.3556 - val_loss: 1.2349 - val_accuracy: 0.5556\n",
      "Epoch 22/150\n",
      "90/90 [==============================] - 0s 233us/step - loss: 1.2876 - accuracy: 0.3556 - val_loss: 1.2258 - val_accuracy: 0.5556\n",
      "Epoch 23/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 1.2740 - accuracy: 0.3667 - val_loss: 1.2180 - val_accuracy: 0.5556\n",
      "Epoch 24/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 1.2615 - accuracy: 0.3667 - val_loss: 1.2097 - val_accuracy: 0.5556\n",
      "Epoch 25/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 1.2489 - accuracy: 0.4000 - val_loss: 1.2023 - val_accuracy: 0.5278\n",
      "Epoch 26/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.2388 - accuracy: 0.4111 - val_loss: 1.1946 - val_accuracy: 0.5278\n",
      "Epoch 27/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 1.2273 - accuracy: 0.4111 - val_loss: 1.1870 - val_accuracy: 0.4722\n",
      "Epoch 28/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 1.2179 - accuracy: 0.4000 - val_loss: 1.1798 - val_accuracy: 0.4722\n",
      "Epoch 29/150\n",
      "90/90 [==============================] - 0s 228us/step - loss: 1.2080 - accuracy: 0.4444 - val_loss: 1.1728 - val_accuracy: 0.4722\n",
      "Epoch 30/150\n",
      "90/90 [==============================] - 0s 215us/step - loss: 1.2002 - accuracy: 0.4444 - val_loss: 1.1660 - val_accuracy: 0.4722\n",
      "Epoch 31/150\n",
      "90/90 [==============================] - 0s 210us/step - loss: 1.1911 - accuracy: 0.4556 - val_loss: 1.1596 - val_accuracy: 0.4722\n",
      "Epoch 32/150\n",
      "90/90 [==============================] - 0s 208us/step - loss: 1.1844 - accuracy: 0.4667 - val_loss: 1.1532 - val_accuracy: 0.4722\n",
      "Epoch 33/150\n",
      "90/90 [==============================] - 0s 224us/step - loss: 1.1760 - accuracy: 0.4667 - val_loss: 1.1472 - val_accuracy: 0.4722\n",
      "Epoch 34/150\n",
      "90/90 [==============================] - 0s 215us/step - loss: 1.1691 - accuracy: 0.4444 - val_loss: 1.1414 - val_accuracy: 0.4722\n",
      "Epoch 35/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 1.1628 - accuracy: 0.4333 - val_loss: 1.1357 - val_accuracy: 0.4444\n",
      "Epoch 36/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 1.1558 - accuracy: 0.4111 - val_loss: 1.1302 - val_accuracy: 0.4444\n",
      "Epoch 37/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 1.1499 - accuracy: 0.4111 - val_loss: 1.1250 - val_accuracy: 0.3889\n",
      "Epoch 38/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 1.1433 - accuracy: 0.4111 - val_loss: 1.1201 - val_accuracy: 0.3611\n",
      "Epoch 39/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 1.1376 - accuracy: 0.4000 - val_loss: 1.1152 - val_accuracy: 0.3611\n",
      "Epoch 40/150\n",
      "90/90 [==============================] - 0s 210us/step - loss: 1.1324 - accuracy: 0.4000 - val_loss: 1.1104 - val_accuracy: 0.3889\n",
      "Epoch 41/150\n",
      "90/90 [==============================] - 0s 225us/step - loss: 1.1273 - accuracy: 0.4000 - val_loss: 1.1059 - val_accuracy: 0.3889\n",
      "Epoch 42/150\n",
      "90/90 [==============================] - 0s 210us/step - loss: 1.1213 - accuracy: 0.4000 - val_loss: 1.1015 - val_accuracy: 0.3889\n",
      "Epoch 43/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 1.1164 - accuracy: 0.3889 - val_loss: 1.0971 - val_accuracy: 0.3889\n",
      "Epoch 44/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 1.1120 - accuracy: 0.3667 - val_loss: 1.0930 - val_accuracy: 0.3611\n",
      "Epoch 45/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 1.1073 - accuracy: 0.3556 - val_loss: 1.0889 - val_accuracy: 0.3611\n",
      "Epoch 46/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 1.1022 - accuracy: 0.3556 - val_loss: 1.0849 - val_accuracy: 0.3333\n",
      "Epoch 47/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 1.0979 - accuracy: 0.3556 - val_loss: 1.0811 - val_accuracy: 0.3611\n",
      "Epoch 48/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.0936 - accuracy: 0.3556 - val_loss: 1.0773 - val_accuracy: 0.3611\n",
      "Epoch 49/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 1.0892 - accuracy: 0.3556 - val_loss: 1.0736 - val_accuracy: 0.3611\n",
      "Epoch 50/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 1.0850 - accuracy: 0.3556 - val_loss: 1.0699 - val_accuracy: 0.3611\n",
      "Epoch 51/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 1.0809 - accuracy: 0.3556 - val_loss: 1.0663 - val_accuracy: 0.3611\n",
      "Epoch 52/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 1.0770 - accuracy: 0.3556 - val_loss: 1.0627 - val_accuracy: 0.3611\n",
      "Epoch 53/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 1.0731 - accuracy: 0.3556 - val_loss: 1.0591 - val_accuracy: 0.3611\n",
      "Epoch 54/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 1.0692 - accuracy: 0.3556 - val_loss: 1.0556 - val_accuracy: 0.3611\n",
      "Epoch 55/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 1.0653 - accuracy: 0.3556 - val_loss: 1.0522 - val_accuracy: 0.3611\n",
      "Epoch 56/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 1.0615 - accuracy: 0.3444 - val_loss: 1.0486 - val_accuracy: 0.3056\n",
      "Epoch 57/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 1.0577 - accuracy: 0.3444 - val_loss: 1.0451 - val_accuracy: 0.3056\n",
      "Epoch 58/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 1.0536 - accuracy: 0.3444 - val_loss: 1.0415 - val_accuracy: 0.3056\n",
      "Epoch 59/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 1.0499 - accuracy: 0.3333 - val_loss: 1.0380 - val_accuracy: 0.3056\n",
      "Epoch 60/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 1.0465 - accuracy: 0.3222 - val_loss: 1.0346 - val_accuracy: 0.3056\n",
      "Epoch 61/150\n",
      "90/90 [==============================] - 0s 216us/step - loss: 1.0425 - accuracy: 0.3333 - val_loss: 1.0311 - val_accuracy: 0.3056\n",
      "Epoch 62/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 1.0384 - accuracy: 0.3222 - val_loss: 1.0274 - val_accuracy: 0.3333\n",
      "Epoch 63/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 1.0347 - accuracy: 0.3222 - val_loss: 1.0238 - val_accuracy: 0.3333\n",
      "Epoch 64/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 1.0309 - accuracy: 0.3222 - val_loss: 1.0200 - val_accuracy: 0.3611\n",
      "Epoch 65/150\n",
      "90/90 [==============================] - 0s 216us/step - loss: 1.0271 - accuracy: 0.3111 - val_loss: 1.0162 - val_accuracy: 0.3611\n",
      "Epoch 66/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 1.0233 - accuracy: 0.2889 - val_loss: 1.0126 - val_accuracy: 0.3611\n",
      "Epoch 67/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 1.0194 - accuracy: 0.3111 - val_loss: 1.0087 - val_accuracy: 0.3611\n",
      "Epoch 68/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 1.0154 - accuracy: 0.3333 - val_loss: 1.0051 - val_accuracy: 0.3611\n",
      "Epoch 69/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 1.0113 - accuracy: 0.3444 - val_loss: 1.0012 - val_accuracy: 0.3889\n",
      "Epoch 70/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 1.0074 - accuracy: 0.3556 - val_loss: 0.9972 - val_accuracy: 0.3889\n",
      "Epoch 71/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 1.0033 - accuracy: 0.3556 - val_loss: 0.9933 - val_accuracy: 0.3889\n",
      "Epoch 72/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.9994 - accuracy: 0.3444 - val_loss: 0.9895 - val_accuracy: 0.4167\n",
      "Epoch 73/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.9949 - accuracy: 0.3778 - val_loss: 0.9855 - val_accuracy: 0.5278\n",
      "Epoch 74/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.9908 - accuracy: 0.4444 - val_loss: 0.9812 - val_accuracy: 0.5556\n",
      "Epoch 75/150\n",
      "90/90 [==============================] - 0s 215us/step - loss: 0.9865 - accuracy: 0.4444 - val_loss: 0.9770 - val_accuracy: 0.5278\n",
      "Epoch 76/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.9821 - accuracy: 0.4556 - val_loss: 0.9729 - val_accuracy: 0.5000\n",
      "Epoch 77/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 0.9781 - accuracy: 0.4667 - val_loss: 0.9682 - val_accuracy: 0.6111\n",
      "Epoch 78/150\n",
      "90/90 [==============================] - 0s 249us/step - loss: 0.9730 - accuracy: 0.5111 - val_loss: 0.9639 - val_accuracy: 0.6389\n",
      "Epoch 79/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.9687 - accuracy: 0.5333 - val_loss: 0.9597 - val_accuracy: 0.6389\n",
      "Epoch 80/150\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.9639 - accuracy: 0.6000 - val_loss: 0.9552 - val_accuracy: 0.6667\n",
      "Epoch 81/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.9591 - accuracy: 0.6222 - val_loss: 0.9507 - val_accuracy: 0.6944\n",
      "Epoch 82/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.9548 - accuracy: 0.6444 - val_loss: 0.9458 - val_accuracy: 0.6944\n",
      "Epoch 83/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 0.9495 - accuracy: 0.6556 - val_loss: 0.9410 - val_accuracy: 0.6944\n",
      "Epoch 84/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.9447 - accuracy: 0.6667 - val_loss: 0.9362 - val_accuracy: 0.7222\n",
      "Epoch 85/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 0.9398 - accuracy: 0.6667 - val_loss: 0.9313 - val_accuracy: 0.7222\n",
      "Epoch 86/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.9344 - accuracy: 0.6778 - val_loss: 0.9264 - val_accuracy: 0.7222\n",
      "Epoch 87/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.9293 - accuracy: 0.7000 - val_loss: 0.9214 - val_accuracy: 0.7222\n",
      "Epoch 88/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.9241 - accuracy: 0.7000 - val_loss: 0.9164 - val_accuracy: 0.7222\n",
      "Epoch 89/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.9187 - accuracy: 0.7000 - val_loss: 0.9113 - val_accuracy: 0.7222\n",
      "Epoch 90/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.9135 - accuracy: 0.7000 - val_loss: 0.9062 - val_accuracy: 0.7222\n",
      "Epoch 91/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.9078 - accuracy: 0.7000 - val_loss: 0.9008 - val_accuracy: 0.7222\n",
      "Epoch 92/150\n",
      "90/90 [==============================] - 0s 211us/step - loss: 0.9025 - accuracy: 0.7000 - val_loss: 0.8956 - val_accuracy: 0.7222\n",
      "Epoch 93/150\n",
      "90/90 [==============================] - 0s 207us/step - loss: 0.8967 - accuracy: 0.7000 - val_loss: 0.8900 - val_accuracy: 0.7222\n",
      "Epoch 94/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.8912 - accuracy: 0.7000 - val_loss: 0.8847 - val_accuracy: 0.7222\n",
      "Epoch 95/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.8854 - accuracy: 0.7000 - val_loss: 0.8792 - val_accuracy: 0.7222\n",
      "Epoch 96/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.8795 - accuracy: 0.7000 - val_loss: 0.8738 - val_accuracy: 0.7222\n",
      "Epoch 97/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 0.8734 - accuracy: 0.7000 - val_loss: 0.8679 - val_accuracy: 0.6944\n",
      "Epoch 98/150\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.8680 - accuracy: 0.7000 - val_loss: 0.8621 - val_accuracy: 0.6944\n",
      "Epoch 99/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.8613 - accuracy: 0.7000 - val_loss: 0.8566 - val_accuracy: 0.6944\n",
      "Epoch 100/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.8553 - accuracy: 0.7000 - val_loss: 0.8507 - val_accuracy: 0.6944\n",
      "Epoch 101/150\n",
      "90/90 [==============================] - 0s 230us/step - loss: 0.8491 - accuracy: 0.7000 - val_loss: 0.8447 - val_accuracy: 0.6944\n",
      "Epoch 102/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.8432 - accuracy: 0.7000 - val_loss: 0.8387 - val_accuracy: 0.6944\n",
      "Epoch 103/150\n",
      "90/90 [==============================] - 0s 219us/step - loss: 0.8374 - accuracy: 0.7000 - val_loss: 0.8329 - val_accuracy: 0.6944\n",
      "Epoch 104/150\n",
      "90/90 [==============================] - 0s 215us/step - loss: 0.8316 - accuracy: 0.6889 - val_loss: 0.8268 - val_accuracy: 0.6944\n",
      "Epoch 105/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.8256 - accuracy: 0.6889 - val_loss: 0.8211 - val_accuracy: 0.6944\n",
      "Epoch 106/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.8200 - accuracy: 0.6889 - val_loss: 0.8156 - val_accuracy: 0.6944\n",
      "Epoch 107/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.8146 - accuracy: 0.6889 - val_loss: 0.8101 - val_accuracy: 0.6944\n",
      "Epoch 108/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.8091 - accuracy: 0.6889 - val_loss: 0.8043 - val_accuracy: 0.6944\n",
      "Epoch 109/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.8038 - accuracy: 0.6889 - val_loss: 0.7990 - val_accuracy: 0.6944\n",
      "Epoch 110/150\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.7989 - accuracy: 0.6889 - val_loss: 0.7936 - val_accuracy: 0.6944\n",
      "Epoch 111/150\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.7940 - accuracy: 0.6889 - val_loss: 0.7880 - val_accuracy: 0.6944\n",
      "Epoch 112/150\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.7887 - accuracy: 0.6889 - val_loss: 0.7834 - val_accuracy: 0.6944\n",
      "Epoch 113/150\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.7836 - accuracy: 0.6889 - val_loss: 0.7784 - val_accuracy: 0.6944\n",
      "Epoch 114/150\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.7789 - accuracy: 0.6889 - val_loss: 0.7734 - val_accuracy: 0.6944\n",
      "Epoch 115/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.7741 - accuracy: 0.6889 - val_loss: 0.7687 - val_accuracy: 0.6944\n",
      "Epoch 116/150\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.7695 - accuracy: 0.6889 - val_loss: 0.7637 - val_accuracy: 0.6944\n",
      "Epoch 117/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.7652 - accuracy: 0.6889 - val_loss: 0.7589 - val_accuracy: 0.6944\n",
      "Epoch 118/150\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.7607 - accuracy: 0.6778 - val_loss: 0.7545 - val_accuracy: 0.6944\n",
      "Epoch 119/150\n",
      "90/90 [==============================] - 0s 193us/step - loss: 0.7564 - accuracy: 0.6778 - val_loss: 0.7502 - val_accuracy: 0.6944\n",
      "Epoch 120/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.7525 - accuracy: 0.6778 - val_loss: 0.7460 - val_accuracy: 0.6944\n",
      "Epoch 121/150\n",
      "90/90 [==============================] - 0s 205us/step - loss: 0.7484 - accuracy: 0.6778 - val_loss: 0.7419 - val_accuracy: 0.6944\n",
      "Epoch 122/150\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.7447 - accuracy: 0.6778 - val_loss: 0.7380 - val_accuracy: 0.6944\n",
      "Epoch 123/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.7405 - accuracy: 0.6778 - val_loss: 0.7340 - val_accuracy: 0.6944\n",
      "Epoch 124/150\n",
      "90/90 [==============================] - 0s 225us/step - loss: 0.7367 - accuracy: 0.6778 - val_loss: 0.7301 - val_accuracy: 0.6944\n",
      "Epoch 125/150\n",
      "90/90 [==============================] - 0s 233us/step - loss: 0.7328 - accuracy: 0.6778 - val_loss: 0.7263 - val_accuracy: 0.6944\n",
      "Epoch 126/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.7294 - accuracy: 0.6778 - val_loss: 0.7225 - val_accuracy: 0.6944\n",
      "Epoch 127/150\n",
      "90/90 [==============================] - 0s 212us/step - loss: 0.7256 - accuracy: 0.6778 - val_loss: 0.7189 - val_accuracy: 0.6944\n",
      "Epoch 128/150\n",
      "90/90 [==============================] - 0s 219us/step - loss: 0.7221 - accuracy: 0.6778 - val_loss: 0.7155 - val_accuracy: 0.6944\n",
      "Epoch 129/150\n",
      "90/90 [==============================] - 0s 220us/step - loss: 0.7187 - accuracy: 0.6778 - val_loss: 0.7120 - val_accuracy: 0.6944\n",
      "Epoch 130/150\n",
      "90/90 [==============================] - 0s 225us/step - loss: 0.7154 - accuracy: 0.6778 - val_loss: 0.7086 - val_accuracy: 0.6944\n",
      "Epoch 131/150\n",
      "90/90 [==============================] - 0s 213us/step - loss: 0.7119 - accuracy: 0.6778 - val_loss: 0.7051 - val_accuracy: 0.6944\n",
      "Epoch 132/150\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.7087 - accuracy: 0.6778 - val_loss: 0.7018 - val_accuracy: 0.6944\n",
      "Epoch 133/150\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.7053 - accuracy: 0.6778 - val_loss: 0.6986 - val_accuracy: 0.6944\n",
      "Epoch 134/150\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.7023 - accuracy: 0.6778 - val_loss: 0.6956 - val_accuracy: 0.6944\n",
      "Epoch 135/150\n",
      "90/90 [==============================] - 0s 212us/step - loss: 0.6992 - accuracy: 0.6778 - val_loss: 0.6926 - val_accuracy: 0.6944\n",
      "Epoch 136/150\n",
      "90/90 [==============================] - 0s 226us/step - loss: 0.6961 - accuracy: 0.6778 - val_loss: 0.6895 - val_accuracy: 0.6944\n",
      "Epoch 137/150\n",
      "90/90 [==============================] - 0s 216us/step - loss: 0.6930 - accuracy: 0.6778 - val_loss: 0.6866 - val_accuracy: 0.6944\n",
      "Epoch 138/150\n",
      "90/90 [==============================] - 0s 224us/step - loss: 0.6902 - accuracy: 0.6778 - val_loss: 0.6837 - val_accuracy: 0.6944\n",
      "Epoch 139/150\n",
      "90/90 [==============================] - 0s 229us/step - loss: 0.6872 - accuracy: 0.6778 - val_loss: 0.6806 - val_accuracy: 0.6944\n",
      "Epoch 140/150\n",
      "90/90 [==============================] - 0s 216us/step - loss: 0.6845 - accuracy: 0.6778 - val_loss: 0.6778 - val_accuracy: 0.6944\n",
      "Epoch 141/150\n",
      "90/90 [==============================] - 0s 221us/step - loss: 0.6816 - accuracy: 0.6778 - val_loss: 0.6751 - val_accuracy: 0.6944\n",
      "Epoch 142/150\n",
      "90/90 [==============================] - 0s 213us/step - loss: 0.6787 - accuracy: 0.6778 - val_loss: 0.6727 - val_accuracy: 0.6944\n",
      "Epoch 143/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.6760 - accuracy: 0.6778 - val_loss: 0.6704 - val_accuracy: 0.6944\n",
      "Epoch 144/150\n",
      "90/90 [==============================] - 0s 219us/step - loss: 0.6732 - accuracy: 0.6778 - val_loss: 0.6680 - val_accuracy: 0.6944\n",
      "Epoch 145/150\n",
      "90/90 [==============================] - 0s 201us/step - loss: 0.6703 - accuracy: 0.6778 - val_loss: 0.6656 - val_accuracy: 0.6944\n",
      "Epoch 146/150\n",
      "90/90 [==============================] - 0s 214us/step - loss: 0.6679 - accuracy: 0.6778 - val_loss: 0.6633 - val_accuracy: 0.6944\n",
      "Epoch 147/150\n",
      "90/90 [==============================] - 0s 227us/step - loss: 0.6649 - accuracy: 0.6778 - val_loss: 0.6608 - val_accuracy: 0.6944\n",
      "Epoch 148/150\n",
      "90/90 [==============================] - 0s 216us/step - loss: 0.6624 - accuracy: 0.6778 - val_loss: 0.6582 - val_accuracy: 0.6944\n",
      "Epoch 149/150\n",
      "90/90 [==============================] - 0s 210us/step - loss: 0.6596 - accuracy: 0.6778 - val_loss: 0.6559 - val_accuracy: 0.6944\n",
      "Epoch 150/150\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.6569 - accuracy: 0.6778 - val_loss: 0.6536 - val_accuracy: 0.6944\n"
     ]
    }
   ],
   "source": [
    "model2 = model_2()\n",
    "history2 = model2.fit(x_train, y_train, epochs = 150, batch_size=10, \n",
    "                   validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84950799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 63us/step\n",
      "accuracy 58.33333134651184\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.evaluate(x_test, y_test)\n",
    "print(model2.metrics_names[1], score2[1]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
